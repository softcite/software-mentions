<tei xmlns="http://www.tei-c.org/ns/1.0"><teiHeader><fileDesc xml:id="10.1257%2Fjep.2.1.153" /><encodingDesc><appInfo><application version="0.5.3-SNAPSHOT" ident="GROBID" when="2018-11-12T00:00+0000"><ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref></application></appInfo></encodingDesc></teiHeader>
<text xml:lang="en">


<p>Economic Perspectives </p>

<p>"extreme bounds analysis," "contract curve analysis," and so on in his SEARCH 
program; 2 all these had a familiar and reassuring ring to economists. 
Poirier goes at it a different way, appealing more to the latent statistician that he 
hopes is lurking behind every economist. Like a good fundamentalist preacher he 
demands, "Do you believe in the Likelihood Principle?" As with most doctrines, we 
give it a quick glance and reply, "Amen, brother." This induces the sermon. From 
there on we are trapped and led inexorably, via the creed of the likelihood principle 
(LP), to the one true religion of Bayesianism. Any who have read C. S. Lewis's 
account of his conversion to Christianity in Surprised By Joy will recognize the process. </p>

<p>Before I begin my critique let me compliment the preacher on his sermon. I 
doubt if one could find a more engaging, beguiling or coherent account of the 
strengths of following the Bayesian methodology. Moreover, it is very well organized 
and contains references rarely read by those econometricians who do not stray too far 
into the debates of statistics. It would be a rare econometrician who would not learn 
something from reading it and it would have to be made essential reading for any 
course that ventured to discuss methodological issues. 
My job here, however, is neither just to praise Caesar nor can I hope to bury him. 
If outstanding statisticians have failed to come to any agreement about these matters 
after a century of argument, the probability that I will have anything of significance 
to add to the debate is so close to zero as to be indistinguishable from it. What follows 
then is certainly not a deep analysis of the issues raised by the paper. If anything it is 
a personal testimony concerning what bothers me about the dogmas of the recom-
mended religion. 
First, let us begin with the LP and example number 1B. Suppose I wanted to test 
H 0 : θ = .5 vs H 1 : θ &gt; .5. To do that one constructs an index and compares its value 
using the data with the value it would be expected to attain if θ were .5. Many such 
indices are used in econometrics. Frequently they are based upon the score function 
(the first derivative of the log likelihood with respect to θ), d log L/dθ, as this entity 
will, on average, be zero when evaluated at θ = .5. Now the likelihood principle says 
that, given two likelihoods, L 1 and L 2 , that are scalar multiples of each other-that 
is, L 1 = cL 2 -then the "evidence" in the two experiments corresponding to the two 
likelihoods is the same. In such a situation log L 1 = log c + log L 2 , making the scores </p>

<p>d log L 1 /dθ and d logL 2 /dθ equal. </p>

<p>I like to think of hypothesis testing as involving two distinct stages. In the first, an 
index such as described above is computed and I find it natural to refer to this as the 
evidence. In the second, a decision is made about the hypothesis based upon this 
evidence. Because Poirier's example 1B features scores, and hence indexes, that are 
numerically identical owing to proportionality of likelihoods, I would conclude that 
the evidence about H 0 is the same in each experiment. But to make a decision about 
H 0 it is necessary to consider the alternative types of data that might have been 
generated, which means by reference to the distribution of the random variable </p>

<p>2 <rs corresp="#software-2" type="creator">Leamer</rs> (1978) describes a program, <rs id="software-2" type="software">SEARCH</rs>, to implement the ideas of that book, and it was used for 
the example in Leamer (1983). </p>

<p>Pagan 155 </p>

<p>responsible for generating the data under H 0 . Because of this, different decisions in the 
context of Example 1B would be made depending upon whether the H 0 data was 
believed to have been generated by a binomial or a negative binomial density. 
To me this is as it should be, and I interpret Example 1B as illustrative of some 
semantic problems arising with the LP rather then the death-knell for frequentist 
statistics. In particular, the LP's use of the term evidence seems to me to be 
misleading. If I interpret "evidence" in the way I have done above, then the 
frequentist approach would be fully concordant with the LP, making me a subscriber 
to the latter, since the index used to assess H 0 is invariant to the experiment. But if 
one incorporates a decision into the term "evidence," then I clearly would not want to 
accept the LP dogma. This shows just how easy it is to get carried away in the fervor 
of a crusade. </p>

<p>Of course, the discrepancy arises from the LP's advocacy of conditioning upon 
the data. Decisions are made only with regard to the data in hand. A frequentist 
statistician uses the data when computing an index, but then claims that no decision 
can be made without thinking of the alternative ways the data might have been 
generated. Even then differences between the LP and frequentist approaches need not 
arise. If the distribution of the index is independent of the nature of the density 
generating the observations, conflicts such as those in Example 1B could never 
happen. With a large enough sample suitably constructed indexes would be ap-
proximately normal in both experiments, and so the same decision would be made 
about H 0 . In fact, it is well known that the posterior density coincides with the 
asymptotic density of the MLE for many cases (Walker, 1969). Whenever one has this 
situation, there can be no difference between the LP and the frequentist approach. </p>

<p>Let me emphasize this point with Poirier's Example 2. He envisages a case where 
it is known that a Tobit model generates the data, but only positive observations 
actually occur, so that a maximum likelihood estimate is found by regression on the 
(positive) observations. Now a frequentist statistician would maintain that the fact 
that the observed sample did not contain any zeroes should not blind us to the fact 
that they could have occurred. Just because the sample is sufficiently small that no 
zeroes have been forthcoming does not mean that we should ignore the fact that our 
sample is a "selected" one in which only high error individuals happen to have been 
included. Such "sample selectivity" should be allowed for in deciding on any 
hypothesis. Once again, looking beyond the data on hand in order to make a correct 
decision seems to me to be the appropriate thing to do. 
All of the above is not to deny that there can be problems with frequentist 
procedures. As Poirier observes, there is a tendency for researchers to speak as if they 
really were making decisions only with reference to the data on hand. Within the 
regression context of y t = x t β + e t , statements such as "strong support for the null 
hypothesis from the data," seem to imply that it is believed that a p-value 
3 tells </p>

<p>3 A p-value is the probability that the computed value of the index selected to assess the hypothesis could 
have come from the distribution that this index would exhibit if the hypothesis were true. Most basic 
statistics texts discuss the concept. </p>



<p>Economic Perspectives </p>

<p>something about Pr(H 0 /y, x). In fact it is really informative only about Pr(H 0 /x), 
since it looks beyond the particular e t observed (that is, y t ) to the other possible e t 's 
that might have eventuated if e t is regarded as (say) a normally distributed random 
variable. If one really wants the first probability, and there are cases where that may 
well be what is most useful, then it is to a Bayesian analysis one should go. If this is 
not done, Tables in Berger and Sellke (1987) show quite dramatically how misleading 
a p-value can be for Pr(H 0 /y, x), particularly if one attaches equal probability to H 0 
and H 1 . 
There is, however, a wider issue here and that is whether we should really be 
interested in Pr(H 0 /y, x) or Pr(H 0 /x) at all. The affirmative case derives from the 
fact that researchers all too often act as if the questions of the economics discipline are 
most usefully analysed by partitioning the parameter space into a point (say θ equals 
zero or unity) and the remainder; for example in all the debate over policy 
effectiveness (θ = 0) or efficient markets (θ = 1). McCloskey's (1985) rubbishing of 
this tendency should be a salutary reminder to us that such a fixation can be quite 
ridiculous, and a more pertinent question to ask is what range of values of θ is likely 
given the observations. The provision of this information is one of the strengths of the 
Bayesian methodology. Recently, Andrews (1986) has made an interesting attempt to 
use the frequentist framework for the same purpose. </p>

<p>Although it takes up a lot of space the LP is really not what Poirier's paper is 
about. The LP is a slogan and not to be confused with the true message. Like a hymn, 
its role is to get us in the right frame of mind so that we can be receptive to the 
doctrines revealed later in the paper. Unfortunately, Poirier immediately reveals 
himself to be a heretic in his central doctrine (PPMB 2). That priors should be subject 
to some type of sensitivity analysis seems perfectly sensible to me, but is anathema to 
the high priests of Bayesianism-witness the fact that the principal exponent of this 
viewpoint, Ed Learner, is rarely asked to the altar when "true Bayesians" meet to pay 
homage to their creator, and never asked to officiate there. In fact, what Poirier really 
gives us in this paper is what I would call "eclectic Bayesianism," and it is not all 
clear what its foundations are. For example, we are told that the prior is "more 
convenient than precise." Later he describes a "post-data prior" that really exists 
before the data, but researchers actually needed to see the data before they realized 
what is was that they knew beforehand... After such a tortuous rationalization, the 
problems that Poirier professes to see in frequentist statistics seem to be rather 
straightforward, and it is hard for me to see why I should be happier with his current 
religion rather that the older one I am used to. 
Moreover, all this is running perilously close to allowing the prior to depend 
upon the sample (within an -neighborhood in my opinion), in which case "eclectic 
Bayesianism" would be condemned on the grounds that it too fails to adhere to the 
LP. I personally feel that Poirier's brand of Bayesianism makes a lot more sense than 
the pure version, particularly his recognition that it is hard to believe that economists 
possess the precise knowledge of a likelihood and prior demanded by the formation of 
a posterior. But this acknowledgement leads him to concern about prior sensitivity 
(PPMB 4) and the use of pure significance tests (PPMB 5), neither of which has any </p>

<p>Dogma or Doubt 157 </p>

<p>Bayesian foundation. After all this sinning he can scarcely adopt the "purer than 
thou" attitude that he does. Once the move to be ecumenical has begun it is hard to 
revert to the old hard-line religion that representatives of Bayesian analysis generally 
demanded of its promulgators, and it makes it difficult to accept the modified creed on 
the basis of the same arguments as are made for its parent. "Eclectic Bayesianism" 
may be a good approach to empirical modeling, but it has no firmer foundations than 
frequentist statistics. 
In fact, I have become increasingly convinced that the same sort of problems 
bedevil all methodologies once we attempt to put them into practice. Just take the 
"pre-test" problem that bothers Poirier. This is really two problems. One is how to 
choose a model out of a set of alternatives; the other is how to interpret the resulting 
statistics associated with the chosen model. The first of these issues requires a 
frequentist to set a threshold or critical value for the indexes discussed earlier; if this 
value is exceeded one model would be rejected in favor of another. 
To appreciate what is involved in the second, one needs to make the distinction 
between Pr(H 0 /x, M 0 ), the probability of H 0 holding conditional upon a chosen 
model M 0 and Pr(H 0 /x, M 0 ,..., M k ), the probability of H 0 holding if we have 
actually arrived at model M 0 after estimating models M 1 ,..., M k . These two prob-
abilities, referred to as conditional and unconditional, are generally not the same. 
Conceptually, either can be calculated in the frequentist framework. The conditional 
probability is a standard item in computer packages, while the unconditional prob-
ability could be found by recourse to computer-intensive simulation methods (Veall, 
1986). In practice, researchers seem to prefer to report the value of Pr(H 0 /x, M 0 ). 
Provided that it is recognized that what is being reported is a probability conditional 
upon the chosen model, this seems satisfactory. I suspect that most readers already 
give the latter interpretation anyway, so that search for unconditional (across models) 
probabilities would be irrelevant. 
How does an "eclectic Bayesian" solve these same two problems? The answer is 
in exactly the same way. To choose between models he has to use some rule. Posterior 
odds is his index, but unless some critical value is set no decision would be made. 
Furthermore, the Pr(H 0 /y, x) associated with the posterior density is quite clearly one 
that is conditional upon the chosen model and makes no allowance for the fact that a 
series of models may have actually been analyzed. Thus the "pre-test" problem occurs 
as much in "eclectic Bayesianism" as in frequentist statistics, and it tends to be 
resolved in identical ways. 
Some of my oldest friends are totally dedicated to a set of religious and political 
principles and everything they do stems from that base. This yields a remarkable 
consistency in thought and action, and an attractive position to which to aspire. But 
whenever I try to do the same thing I find that doubt about the central dogmas starts 
creeping in, and I end up with a collection of rather contradictory principles. 
However, I doubt that my decision making would be much improved if I could 
manage to be consistent with a basic set of underlying beliefs. I am convinced that 
much the same thing happens in econometric modeling. Some people put a premium 
upon consistency and seek the core set of doctrines that will always achieve that result. </p>



<p>It seems to be this position that motivates Poirier, even if he does hedge a bit at times. 
If you are one of this sort of people his position might appeal to you. If you are not, 
then you can probably console yourself with Blackwell's reply to de Groot's question 
about whether Bayesian statistics was much discussed at Berkeley (de Groot, 1986, 
p. 48): "Not really. It used to be discussed here but you soon discover that it's sort of 
like religion; that it has an appeal for some people and not for other people, and 
you're not going to change anybody's mind by discussing it." </p>



<p>This article has been cited by: </p>

<p>1. Harald Uhlig. 1994. What Macroeconomists Should Know about Unit Roots: A Bayesian Perspective. 
Econometric Theory 10:3-4, 645. [CrossRef] </p>

<p>2. James H. Stock. 1991. Bayesian approaches to the 'unit root' problem: A comment. Journal of Applied 
Econometrics 6:4, 403-411. [CrossRef] </p>

<p>3. Peter Kennedy, Daniel Simons. 1991. Fighting the teflon factor. Journal of Econometrics 48:1-2, 15-27. 
[CrossRef] </p>

</text></tei>