<tei xmlns="http://www.tei-c.org/ns/1.0"><teiHeader><fileDesc xml:id="PMC3035800" /><encodingDesc><appInfo><application version="0.5.6-SNAPSHOT" ident="GROBID" when="2019-06-04T06:37+0000"><ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref></application></appInfo></encodingDesc></teiHeader>
<text xml:lang="en">
<p><rs type="software">Ct3d</rs>ABSTRACT </p>

<p>Motivation: Cell tracking is an important method to quantitatively 
analyze time-lapse microscopy data. While numerous methods and 
tools exist for tracking cells in 2D time-lapse images, only few and 
very application-specific tracking tools are available for 3D time-
lapse images, which is of high relevance in immunoimaging, in 
particular for studying the motility of microglia in vivo. 
Results: We introduce a novel algorithm for tracking cells in 3D 
time-lapse microscopy data, based on computing cosegmentations 
between component trees representing individual time frames using 
the so-called tree-assignments. For the first time, our method 
allows to track microglia in three dimensional confocal time-lapse 
microscopy images. We also evaluate our method on synthetically 
generated data, demonstrating that our algorithm is robust even in 
the presence of different types of inhomogeneous background noise. 
<rs id="software-20" type="software">ct3d</rs><rs corresp="#software-20" type="url">http://www.picb.ac.cn/patterns/Software/ct3d</rs>Capturing the motility of cells using time-lapse microscopy has 
become an important approach to understanding processes such 
as the cell cycle (Harder et al., 2009), neuronal division and 
migration (Norden et al., 2009), immune response (Cahalan and 
Parker, 2008) or the development of cancer (Ianzini et al., 2009). 
Based on phase-contrast, confocal or two-photon microscopy, such 
live cell imaging protocols are now commonly established and 
corresponding equipment is commonly available. This has triggered 
the need for computational methods to quantitatively analyze time-
lapse microscopy data. In this context, identifying individual cells 
and tracking their identities over time is one of the basic ingredients 
for computational analysis. Hence, cell tracking algorithms have </p>

<p> *  To whom correspondence should be addressed. 
 † The authors wish it to be known that, in their opinion, the first two authors 
should be regarded as joint First Authors. </p>

<p>attracted considerable attention in recent years (Meijering et al., 
2006; Miura, 2005). Here, we introduce a novel algorithm for cell 
tracking that allows to track cells, in particular zebrafish microglia, 
in 3D two-photon image sequences over time. 
The majority of cell tracking algorithms, as surveyed by Meijering 
et al. (2006) or Miura (2005), deals with cell tracking in 2D over 
time. Methods range from linking cells identified in individual 
frames using different segmentation approaches to active-contour 
(Dufour et al., 2005; Sacan et al., 2008; Shen et al., 2006) or 
level-set algorithms (Dzyubachyk et al., 2008; Li et al., 2008b; 
Mukherjee et al., 2004; Nath et al., 2006). The challenges imposed 
by the nature of the images to be analyzed lie in phenomena such 
as cell divisions (Al-Kofahi et al., 2006; Li et al., 2008a), cells 
entering or leaving the displayed area, or a large number of cells 
that needs to be tracked simultaneously. In addition, cell tracking 
is often complicated by background inhomogeneity, for instance 
due to uneven illumination (Leong et al., 2003), and cells touching 
each other. While these issues have been addressed extensively for 
tracking cells in 2D, surprisingly few approaches have addressed 
cell tracking in 3D. Besides naive thresholding approaches, there 
are only few advanced approaches, such as the active-contour 
based method proposed by Dufour et al. (2005). Recently, several 
authors (Jaensch et al., 2010; Kerekes et al., 2009) proposed 
reliable methods for tracking centrosomes in Caenorhabditise 
legans embryos. Yet, these approaches are tailored toward tracking 
small, bright and circular objects which e.g. resemble a Gaussian 
spot of a specific size. Such assumptions, however, are not satisfied 
by the complex and highly variable shapes of microglia under 
consideration here. Cell tracking is also relevant in the context of 
tracking cell populations in vitro, which has attracted considerable 
attention recently (House et al., 2009; Ong et al., 2010; Padfield 
et al., 2009). 
The lack of methods for tracking cells in 3D has been reported 
as a limiting factor, for instance in the context of immunoimaging 
(Cahalan and Parker, 2008). Despite the well-established protocol to 
capture microglia, innate immune cells in the central nervous system, 
in 3D using two-photon microscopy following the seminal works 
by Nimmerjahn et al. (2005) and Davalos et al. (2005), motility 
analysis has been performed by (and limited to) manual estimations 
derived from 2D projections (Davalos et al., 2008) in the numerous 
studies following these protocols. In fact, tracking microglia cells is 
complicated by several aspects. Microglia tightly contact specific 
brain structures in their resting state (Wake et al., 2009), often 
making it difficult to clearly separate them from their surrounding </p>

<p>© The Author(s) 2010. Published by Oxford University Press. 
This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/ 
by-nc/2.5), which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited. </p>



<p>Fig. 1. 3D motion patterns of two microglia in vivo reconstructed using 
<rs type="software">ct3d</rs>. The red and green areas indicate initial positions of the two microglia. 
While the red cell remains in resting state, the green cell is activated through 
an induced injury and migrates along a trajectory (orange line, trajectory 
obtained by <rs type="software">ct3d</rs>; blue line, trajectory obtained from manual annotation) 
toward a site of injury (purple dot); see Supplementary Video 1 for a rendered 
animation of the same data. </p>

<p>tissue. Furthermore, the extension and retraction of the so-called 
microglia processes makes it practically impossible to separate them 
from other cells or surrounding tissues in a 2D projection. As we 
demonstrate in this study, cosegmentation-based cell tracking may 
overcome these difficulties and allows to reliably track microglia 
in 3D, both in resting state and when moving in activated state, as 
displayed in Figure 1. 
From an algorithmic point of view, our method can be seen 
as a broad generalization of thresholding methods. Otsu's early 
and still commonly used approach (Otsu, 1975) picks a cut-off 
intensity based on the gray-value histogram of an image, considering 
pixel intensities below this threshold as background and pixels 
exceeding the threshold intensity as foreground. To deal with 
background inhomogeneities and objects of varying intensities, 
different approaches such as locally adaptive thresholding (Kim 
and Park, 2005) have been developed. Our approach utilizes a 
highly systematic way of picking local thresholds in a hierarchical 
representation of all possible thresholds of an image, the so-
called component tree (Jones, 1999; Najman and Couprie, 2004). 
In order to pick local thresholds in the component tree, we 
compare the component trees of consecutive time frames by solving 
the so-called tree assignment problem, a natural generalization 
of bipartite matchings and the associated assignment problem. 
Comparing component trees by computing tree assignments yields 
a cosegmentation of two images; for cell tracking, cosegmentations 
between two time frames in a video sequence are of particular 
relevance. 
While the term cosegmentation has been coined by Rother et al. 
(2006), our approach significantly differs from their approach, which </p>

<p>is based on comparing histograms. On the contrary, our approach is 
morphological in the sense that it attempts to identify overlapping 
regions in two images by finding an optimal tree assignment. 
Using cosegmentation has potential further applications in 
location proteomics beyond the cell tracking problem investigated 
in this article. Tree assignments as a generalization of bipartite 
matchings were introduced and applied by the last author 
recently (Mosig et al., 2009), and were recently shown to 
be computationally hard in general (Canzar, Elbassioni and 
Klau, personal communication, 2010). Applying tree assignments 
to component trees for obtaining cosegmentations is a novel 
contribution in this work. In fact, cosegmentations promise to 
be useful in other bioimaging (and eventually image processing) 
applications beyond cell tracking. One straightforward application 
where cosegmentation is of high relevance are protein colocalization 
studies. Studying colocalization has recently become of relevance 
through the availability of corresponding two-or multi-label 
fluorescence microscopy (Schubert et al., 2006; Zinchuk and 
Zinchuk, 2008) or in situ hybridization (Boettiger and Levine, 2009; 
Carson et al., 2009) techniques. 
We implemented our algorithm in the publicly available <rs type="software">ct3d</rs> 
software package, which is accompanied by the <rs type="software">at3d</rs> graphical 
user interface. In terms of applying our algorithm, this article 
focuses on evaluating the performance of our cosegmentation-based 
approach for 3D cell tracking, leaving colocalization studies as a 
future direction. Cell tracking performance is evaluated both on 
two-photon live cell imaging data displaying zebrafish microglia 
in vivo, and on synthetically generated data that allow to determine 
the algorithm's accuracy based on the ground truth the synthetic data 
were generated from. </p>

<p>2 METHODS </p>

<p>2.1 Computational methods </p>

<p>Our algorithm is based on representing each image F 1 ,...,F N by its 
component tree (Jones, 1999). The component tree of an image I is obtained 
by considering the connected components of the thresholded versions I θ of 
I under all possible thresholds θ. The set of all connected components under 
all thresholds is obviously hierarchically ordered by subset inclusion. This 
hierarchical order defines the component tree, which can be computed in 
linear time (Najman and Couprie, 2004). For examples of 1D images and 
their component trees refer to Figure 2. 
Figure 3 illustrates the basic steps of our cell tracking algorithm. The 
outline of the algorithm is as follows: we start with computing and pruning 
component trees for each time frame. Then, tree assignments between each 
pair of consecutive component trees are computed. The tree assignments 
can be turned into segmentations of the original images. This produces 
two segmentations of each image, requiring computation of a consensus 
segmentation. The resulting unique segmentation of each image then requires 
a standard bipartite matching between consecutive time frames to track 
cell identities over time. Details of the individual steps are provided in the 
following paragraphs. 
Computing and pruning component trees: for efficiently computing 
component trees, we relied on established algorithms based on a union-
find data structure (Najman and Couprie, 2004). In order to reduce the size 
and the complexity of the component tree, we apply a pruning procedure 
to these trees. Pruning is a crucial ingredient of our algorithm, as running 
tree assignments on the complete component trees would be computationally 
too demanding. The goal of pruning is thus to eliminate as many vertices 
as possible, keeping only those that reflect the relevant structures of the </p>



<p>H.Xiao et al. </p>

<p>underlying image. This is conceptually closely related to the ideas behind 
component filters (Salembier and Serra, 1995). 
In a first pruning step, we eliminate all vertices that represent a connected 
component of size less than θ min or exceeding θ max , where θ min ,θ max are 
parameters specified by the user. In a typical microscopy setting, loose upper </p>

<p>Fig. 2. Tree assignment of two (pruned) component trees for two 1D images 
I and J. Vertices not eliminated by the second pruning step are indicated by 
circles. All other non-branching vertices are eliminated in the pruning step. 
The tree assignment indicated by the dashed arrows is A ={(a,c),(b,d),(e,f )} 
with a weight of w a,c +w b,d +w e,f . </p>

<p>and lower bounds on the size of the cells to be tracked are usually easy to 
estimate. In practice, these parameters can be chosen quite loosely, with the 
ratio θ max /θ min equal to 10 or larger. 
In a second pruning step, we eliminate all vertices in T i that do not 
occur immediately before or immediately after a branch in the original tree 
(excluding leaves), as indicated in Figure 2. As this might eventually delete 
relevant vertices, we introduce a single node cutoff parameter σ, and keep 
every vertex v with only one child vertex w, if the symmetric difference 
between the areas associated with v and w comprises more than σ many 
pixels. As a rule of thumb, choosing σ&lt;θ min /2 is a good choice, which 
automatically limits the error rate to 50% in the worst case. For better worst-
case guarantees, a smaller fraction of θ min can be chosen. Note that all results 
presented in this work were obtained using σ = 200. 
We consider the size cutoffs θ min and θ max as parameters derived from 
rough estimates on the expected size of the cells to be identified. The main 
purpose is to eliminate vertices that result from noise in the input images, 
where such size cutoffs are known as grain filters (Vincent, 1993) as a specific 
type of connected operators. The expected size of noise components can be 
derived using random graph theory (Coupier et al., 2005). As this is currently 
understood only for 2D images, we treat θ min as a user specified parameter. 
Tree assignments: to obtain cosegmentations of the image pairs F i and 
F i+1 , we compute a tree-assignment between the corresponding component 
trees T i and T i+1 . As illustrated in Figure 2, a tree assignment A i associates 
vertices (i.e. connected components) in T i with vertices in T i+1 . As each 
assignment identifies a component in T i and a component in T i+1 as a putative 
cell, no ancestor or descendant of the matched vertices may be part of a valid 
tree-assignment-otherwise, some area in an image would be occupied by 
two cells. If two assignments involve no overlapping components, we will 
also refer to them as compatible. Naturally, valid tree-assignments can be 
identified as pairwise compatible assignments. More precisely, as the quality </p>

<p>Algorithm cosegmentation-track </p>

<p>• Input: Sequence of images F 1 ,...,F N ; 
pruning parameters θ min ,θ max , single-
node cutoff σ. </p>

<p>• Output: Sequence of segmented images 
S 1 ,...,S N . </p>

<p>(1) Compute component tree T i for all i ∈[1 : 
N]. </p>

<p>(2) Prune T i to obtain T i using θ min ,θ max ,σ. </p>

<p>(3) For each i ∈[1 : N −1], compute A i = 
treeassign(T i ,T i+1 ). </p>

<p>(4) Use A i and A i+1 to obtain two 
segmentations of image F i ; compute 
consensus segmentation S i from these 
two. </p>

<p>(5) For each i ∈[1 : N −1], compute a 
maximum-weighted bipartite matching 
between the segments in S i and S i+1 . </p>

<p>(6) Assign random color to each segment in 
S 1 to obtain S 1 . In S i+1 , assign the same 
color to the segment as the one matched 
in S i . </p>

<p>Fig. 3. Overview of complete cell tracking algorithm. </p>



<p>Ct3d </p>

<p>of an assignment X a,b can be weighted by the relative overlap ω a,b of the 
associated components, we aim to find maximum-weighted sets of pairwise 
compatible assignments. 
Finding maximum weighted pairwise compatible assignments naturally 
translates into an integer linear program by introducing a binary indicator 
variable X a,b for each possible assignment between vertices a and b. The 
linear program is established by introducing one constraint for each root-
leaf path in each of the two trees; the sum of all variables involving any 
vertex along the path must be constraint to at most 1. 
Weights for tree assignments: an important role is taken by the weights 
ω a,b . A straightforward choice is the 'relative overlap' between the 
corresponding areas γ(a) and δ(b), i.e. </p>

<p>ω a,b := |γ(a)∩δ(b)|/|γ(a)∪δ(b)|. </p>

<p>This score is also known as the Jaccard-Index or the Tanimoto Score. An 
important observation is that these weights are restricted to the interval [0,1]. 
For the solution of the tree assignment, this means that in a sense also the 
number of segments identified will be maximized. For weighting schemes 
yielding unbounded values over the real numbers, large and very highly 
scored segments might 'overshadow' many small good assignments in the 
solution. 
For computing all weights between any pair of vertices in two given trees, 
we implemented a fast algorithm utilizing the fact that 0-weighted vertex 
pairs do not require a variable in the linear program, along with the property 
that ω a,b = 0 implies ω a ,b = 0 for all descendants a of a and b of b. This 
leads to a speedup of an order of magnitude compared to a naive way of 
computing all pairwise weights. 
Turning 
tree 
assignments 
into 
cosegmentations: 
assume 
A ={(a 1 ,b 1 ),...,(a K ,b K )} is a tree assignment between the component trees 
of two images I and J. Then, the areas γ(a 1 ),...,γ(a K ) refer to pairwise 
disjoint segments in I, and can hence be considered as a segmentation of 
I. Correspondingly, the areas δ(b 1 ),...,δ(b K ) induce a segmentation of J; 
note that the segments γ(a i ) and δ(b j ) necessarily overlap, as they require a 
non-zero weight to be included in an optimal tree-assignment. 
Consensus segmentation and bipartite matching: when determining a 
segmentation of frame i, we are confronted with two competing options; 
one segmentation P i resulting from the cosegmentation of frames i−1 and i, 
the other one, Q i , from the cosegmentation of frames i and i+1. We resolve 
this by computing a consensus segmentation. We generally use P i as the 
starting point of a consensus segmentation. Any segment in Q i that does not 
overlap with any segment P i is supplement to P i to obtain the consensus 
segmentation P i . This ensures that cells entering the scene in frame i can be 
identified in frame i (rather than frame i+1). 
Filtering results: as for most segmentation and tracking approaches, the 
results obtained from the steps described above has a tendency toward 
overdetection, i.e. detecting segments that result from image noise rather than 
cells. To filter out those segments, we utilize life span filtering, i.e. we filter 
out all cells whose identity can be traced across less than a certain minimum 
number of frames. This cell filter, along with several other ways to eliminate 
cells with unsuitable size or volume features, follows corresponding features 
of the <rs id="software-69" type="software">Celltrack</rs> software (<rs corresp="#software-69" type="creator">Sacan et al.</rs>., 2008) for 2D cell tracking; for 
<rs type="software">ct3d</rs>, they are implemented in the graphical user interface of the <rs type="software">at3d</rs> tool 
shown in Figure 4. </p>

<p>2.2 Comparison with other approaches </p>

<p>While a quantitative comparison with other methods is subject of Section 3, 
there are noteworthy commonalities and differences with other approaches 
on a qualitative level as summarized below: </p>

<p>• Locally adaptive thresholding: deriving a segmentation from 
identifying vertices in a component tree can be seen as a way of locally 
adaptive thresholding; rather than determining local thresholds in pre-
computed regions of interest as in Kim and Park (2005) or windows 
of fixed size, every component represented in the component tree is 
eligible to define a local threshold. </p>

<p>Fig. 4. Screenshot of <rs type="software">at3d</rs>, which is designed for exploring cell tracking 
results and extracting motility parameters. It also supports features for 
correcting overdetection and oversegmentation. Cells can be selected and 
removed either individually or by filtering based on different criteria such as 
size or life span. </p>

<p>• Absence of a global background model: in contrast to both thresholding 
and level-set methods, in particular active-contour approaches, our 
approach does not involve any assumptions regarding the distribution 
of the background intensities. This is particularly useful in the presence 
of background inhomogeneity. </p>

<p>• Alternative matching schemes: one class of cell tracking approaches 
is based on computing bipartite matchings between segmentations of 
individual time frames. As bipartite matchings may not capture events 
such as cell division or cell fusion, recent works such as Padfield et al. 
(2009) introduced alternative matching schemes that are more flexible. 
Truly generalizing bipartite matchings, tree assignments can be seen 
as such alternative matching scheme. They are particularly interesting 
for cell tracking, as they may capture events such as cell division, 
cell fusion or cells entering the scene. See Supplementary Video 4 
for synthetic data displaying a simplistic simulation of a cell division 
tracked by <rs type="software">ct3d</rs>. </p>

<p>2.3 Implementation </p>

<p>We implemented component trees, tree-assignments and the complete cell 
tracking algorithm, in <rs type="software">C++</rs> using <rs type="software">lp_solve</rs> 1 for solving both the tree 
assignment and the weighted bipartite matching (integer) linear programs, 
all of which is compiled in the <rs type="software">ct3d</rs> command line tool. Cell tracking 
results can be further explored using <rs type="software">at3d</rs>, which allows the user to select 
and extract specific cells identified by the cell tracking procedure, and derive 
their motility parameters such as velocity and deformation. The <rs type="software">at3d</rs> tool is 
implemented using the <rs type="software">qt</rs> framework for graphical user interfaces. Input and 
output of image series is designed to be compatible with other visualization 
software, most notably <rs id="software-74" type="software">v3d</rs> (<rs corresp="#software-74" type="creator">Peng et al.</rs>., 2010) for producing rendered 
visualizations of the output. </p>

<p>2.4 Experimental materials and methods </p>

<p>3D time-lapse, two-photon microscopy imaging of zebrafish microglia was 
performed as follows: Zebrafish preparation. Zebrafish Tg(ApoE:egfp), in 
which microglia express EGFP (Peri and Nüsslein-Volhard, 2008), were 
maintained in the National Zebrafish Resources of China (NZRC, Shanghai, 
China) with an automatic fish housing system (ESEN, Beijing, China) at 
28 • C. Embryos were raised at 28.5 • C under a 14/10 h light-dark cycle in </p>

<p>1 http://lpsolve.sourceforge.net/5.5/. </p>



<p>H.Xiao et al. </p>

<p>10% Hanks solution, which consists of (in mM) 140 NaCl, 5.4 KCl, 0.25 
Na2HPO 4 , 0.44 KH 2 PO 4 , 1.3 CaCl 2 , 1.0 MgSO 4 and 4.2 NaHCO 3 (pH 7.2). 
They were staged as previously described (Kimmel et al., 1995). Zebrafish 
handling procedures were approved by Institute of Neuroscience, Shanghai 
Institutes for Biological Sciences, Chinese Academy of Sciences. 
Time-lapse imaging: for in vivo imaging, zebrafish larvae at 5-7 days 
post-fertilization (dpf) were first anesthetized with Hanks solution containing 
0.02% tricaine methanesulfonate (MS222) and embedded in 1.5% low-
melting point agarose. Time-lapse images of microglia were captured, via 
a 40× water objective mounted on a two-photon microscope with 900 nm 
(Prairie) or a Nikon A1R confocal microscope with 488 nm. Z-stack images, 
which covered the whole area of microglia in the optic tectum, were collected 
every 2 min at a section thickness of 1 µm. Each frame (512×512 pixels, 14 
to 34 Z-stack images) was averaged four times. </p>

<p>3 RESULTS </p>

<p>We evaluated our algorithm on two types of data. First, we applied 
it to an in vivo time-lapse sequence of 3D two-photon images of 
zebrafish midbrain, displaying the motility of microglia; second, we 
applied <rs type="software">ct3d</rs> to synthetically generated data for quantifying the 
accuracy of our cell tracking results. 
Evalutation on in vivo data was accomplished by comparison 
with manually annotated trajectories of specific microglia in three 
datasets. Note that manual annotation is limited to trajectories, 
whereas boundaries of the cell volumes are almost impossible to 
obtain in 3D, beside systematic problems with manual annotations 
(Huth et al., 2010). Hence, we additionally created synthetic ground 
truth data to further evaluate the performance of our method. We 
followed the procedure used in Dufour et al. (2005), generating 
(noise perturbed) elliptical objects of average intensity I o above 
Poisson distributed background noise of intensity I b . In addition 
to the procedure from Dufour et al. (2005), we created perturbed 
images with different types of background inhomogeneities, as 
shown in Figure 5: in a second set of data, we introduced a 
multiplicative vignetting effect to the data, following the vignetting 
model by Kang and Weiss (2000) under different focal lengths f 
and off-axis illumination parameters α. In a third set of data, we 
introduced an additive linear gradient along the x-axis of different 
slopes β. Each time series consists of 20 time frames, each of size 
200×200×40 pixels. On these data, we ran <rs type="software">ct3d</rs> with size cutoffs 
θ min = 500 and θ max = 5000, and a single-node cutoff of 200 pixels. 
In the resulting sequences, all cells whose identity could be traced 
through the complete sequence were kept, while all other cells were 
discarded using the <rs type="software">at3d</rs> tool. </p>

<p>3.1 Evaluation on synthetic data </p>

<p>Our results on the synthetically generated image sequences 
are summarized in Table 1 and indicate that <rs type="software">ct3d</rs> is highly 
robust against different types and intensities of background 
inhomogeneities. The results suggest that <rs type="software">ct3d</rs> has a tendency 
to identify components slightly (about 10%) larger than the actual 
objects, as can also be seen in the sample output in Supplementary 
Video 3. This is a natural consequence of pruning the component 
trees, where the vertex that would perfectly represent an object is 
unlikely to be part of the pruned tree. This effect can be reduced by 
smaller choice for the single-node cutoff parameter σ at the cost of 
higher computation time. 
Running times varied between roughly 4 and 6 min, with an 
average of 303.42 s, for completely tracking one dataset. The </p>

<p>Fig. 5. Sections of synthetically generated images-Left: 2D section (top) of 
an image perturbed background vignetting following the Kang-Weiss model 
(Kang and Weiss, 2000). The dashed box indicates the position of the 1D 
section displayed in the lower part. Right: same setting with the background 
perturbed by an additive linear gradient. In both instances, <rs type="software">ct3d</rs> yields 
reliable tracking results (see Table 1). </p>

<p>majority of running time was spent on constructing the component 
trees and computing the overlap weights (14.23 s on average per 
time frame), whereas each tree assignment required less than one 
second on average; the pruned component trees typically comprised 
a few dozens of vertices. 
As a reference algorithm to compare against the performance of 
<rs type="software">ct3d</rs>, we computed a segmentation of each time frame using the 
active contour approach by Chan and Vese (2001), 
2 which is a well-
established and state-of-the-art representative of the large family of 
level set methods. As shown in Table 1, this method works highly 
accurate in the absence of background inhomogeneity while getting 
less reliable with increasing levels of background inhomogeneity, 
as can be expected due to the involvement of a global background 
model. </p>

<p>3.2 Tracking microglia in vivo </p>

<p>Figure 6 shows a result obtained from our tracking algorithm on a 
time series of microglia images measured as described above. We 
reduced resolution by half, so that the resulting width and height 
varied between 146 and 250 pixels, while the depth ranged between 
14 and 66 layers for each time frame; each time series comprised 
30-80 time frames. Gray scale resolution was reduced from 16 bit 
to 8 bit. We applied <rs type="software">ct3d</rs> using parameters θ min = 200, θ max = 
10 000 and a single-node cutoff of 200 pixels; the resulting pruned 
component trees contained 69 vertices on average, ranging between 
40 and 168 vertices. Running times varied between roughly 2 and 
10 min, with 471 s on average. 
Under the given experimental protocol, the phenomenon of 
overdetection, i.e. the recognition of segments that are not microglia, 
is inevitable. This is due to the limited specificity of the apoE-
GFP gene, which is also expressed in cells other than microglia 
in the surrounding tissue, often at comparably high levels as in 
microglia. Yet, <rs type="software">ct3d</rs> identifies microglia as segments that can be 
visually distinguished from non-microglia segments by a human 
observer due to their characteristic shape or motion patterns. The </p>

<p>2 Results were computed for parameters µ = 1, ν = 0.7, λ 1 = 1, λ 2 = 2, t = 
0.8 running 100 iterations. </p>



<p>Ct3d </p>

<p>Table 1. Tracking results for synthetic data </p>

<p>Data Set 
ct3d tracking result 
Chan-Vese result </p>

<p>I o 
I b 
Inhomogeneity 
No. of cells 
Voxel recall (%) 
Error rate (%) 
No. of cells 
Voxel recall (%) 
Error rate (%) </p>

<p>None 
2 
1 
-
3.00 
99.94 
9.86 
3.00 
92.94% 
7.07 
3 
1 
-
3.95 
100.00 
22.93 
3.00 
99.25% 
0.75 
3 
2 
-
3.00 
100.00 
11.48 
3.00 
90.25% 
9.75 
6 
1 
-
3.00 
100.00 
9.74 
3.00 
99.70% 
0.30 
10 
1 
-
3.00 
99.11 
10.05 
3.00 
99.93% 
0.07 </p>

<p>Linear 
3 
1 
β = 2 
3.00 
100.00 
10.62 
2.80 
80.26% 
19.95% 
3 
1 
β = 3 
3.00 
100.00 
4.51 
2.10 
62.97% 
39.00% 
3 
2 
β = 3 
3.00 
99.97 
6.83 
1.95 
58.27% 
42.76% 
6 
1 
β = 3 
3.00 
100.00 
1.27 
2.20 
66.54% 
41.26% </p>

<p>Vignetting 
2 
1 
f = 100,α = 5e−3 
3.00 
98.42 
8.13 
0.85 
22.89% 
77.25% 
2 
1 
f = 200,α = 1e−3 
3.00 
99.96 
9.08 
1.90 
56.56% 
43.60% 
2 
1 
f = 200,α = 5e−3 
3.00 
98.45 
6.80 
0.60 
15.76% 
84.31% 
3 
1 
f = 200,α = 1e−3 
3.00 
100.00 
14.25 
3.00 
93.70% 
6.33% </p>

<p>To assess the quality of tracking results, we derived the number of identified cells, the voxel recall, i.e. what percentage of all ground truth object voxels was recovered in the 
tracking result, as well as the error rate defined as the ratio between the cardinality of the symmetric difference between tracking result and ground truth and the total number 
of voxels in the ground truth dataset. Left columns: each dataset displayed three cells with different intensities I o above different levels of noise I b , displaying different types of 
background inhomogeneities (see text). Middle columns: the three cells were correctly recovered under all settings by <rs type="software">ct3d</rs>. Right columns: segmentation using the active contour 
approach by Chan and Vese (2001) is highly reliable in the absence of background inhomogeneity. With increasing level of inhomogeneity, voxel recall decreases, while the error 
rate increases. Supplementary Figure 1 displays some of the results summarized here. </p>

<p>graphical user interface of the at3d tool (see Fig. 4) allows to 
manually eliminate false positive cells from tracking results by 
different filtering and visual selection functions similar to those 
provided by <rs type="software">Celltrack</rs> for 2D time-lapse sequences. The at3d 
tool also allows to manually correct for the occasionally observed 
events of oversegmentation, i.e. one microglia being recognized as 
two segments. 
We used <rs type="software">at3d</rs> to eliminate non-microglia from all six datasets 
and correct oversegmentation in individual frames. We were able to 
reconstruct trajectories of all relevant microglia that can be visually 
identified in the original datasets; only one dataset was affected by 
a sudden 'frameshift', i.e. the sample changing its distance to the 
camera in the z direction, leading to interrupted trajectories at the 
corresponding time frame. In few other cases, the trajectory of a 
microglia was interrupted in individual frames, which we could 
correct using <rs type="software">at3d</rs>. Examples of the final results are given in 
Supplementary Videos 1 and 2. 
In order to quantitatively evaluate the quality of <rs type="software">ct3d</rs> results 
on in vivo microglia data, we compared <rs type="software">ct3d</rs> trajectories with 
manual annotations. To this end, we selected four microglia from 
four different datasets and annotated their trajectories manually 
using the 3D polyline markup feature of the <rs type="software">v3d</rs> software. The root 
mean square distance between the <rs type="software">ct3d</rs> and the manual trajectories 
turned out to be 2.9 voxels, 5.5 voxels, 2.6 voxels and 5.4 voxels, 
respectively, in the four different datasets. These deviations can be 
considered relatively small in relation to the cell diameters, which 
were measured as 22.8, 22, 19.6 and 44.3 voxels, respectively. 
We also applied the active-contour approach from Chan and Vese 
(2001) to the datasets. Identifying the the four microglia in our 
annotated evaluation dataset required intensive tuning of the four 
major parameters. In fact, we could not identify a single set of 
parameters that works across all datasets. A parameter set tuned 
for a specific dataset worked comparably well on the respective </p>

<p>dataset, but performed significantly worse or yielded no result on 
other datasets, see Figure 6. </p>

<p>4 DISCUSSION </p>

<p>We have presented a novel approach to tracking cells in 3D 
time-lapse microscopy image sequences, based on the concepts 
of component trees and cosegmentation. We demonstrate that this 
approach is robust against the numerous challenges imposed by 
images measured in an in vivo environment, and allows to identify 
microglia and their motion patterns in zebrafish neural tissue 
when combined with the <rs type="software">at3d</rs> annotation tool. In a quantitative 
evaluation, we show that our approach is robust against different 
types of background inhomogeneities. This suggests that <rs type="software">ct3d</rs> and 
<rs type="software">at3d</rs> are potentially useful for in vivo imaging studies investigating 
other aspects than just microglia motility. In its current formulation, 
our cosegmentation approach relies on the assumption that the area 
occupied by an object overlaps between two consecutive time points. 
While this may not be satisfied in all cell tracking problems [e.g. 
when tracking centrosomes (Jaensch et al., 2010)], it is a reasonable 
assumption for many immunoimaging-related studies. 
To the best of our knowledge, our approach is the first that 
can identify and track microglia in live cell imaging time series. 
In most cases, obtaining reliable trajectories still requires manual 
post-processing of the output. The most notorious difficulties 
certainly are the complex morphology-their deformation patterns, 
irregular shapes and interaction with the surrounding-as well as 
the unspecificity of the fluorescent markers available. In this light, 
our approach constitutes significant progress in the sense that it has 
sufficient sensitivity to separate microglia form their surrounding. 
Yet, a fully automated approach remains a major and certainly 
non-trivial challenge. A first step in this direction might be the 
combination with level-set based approaches as utilized for 2D cell </p>



<p>H.Xiao et al. </p>

<p>(a) 
( b) </p>

<p>(d) 
(c) </p>

<p>Fig. 6. Top: visualization of trajectories obtained by manual annotation (blue 
lines) with trajectories obtained using <rs type="software">ct3d</rs> (orange lines) for microglia in 
activated state, see (a) and (b), as well as resting state, see (c) and (d). 
Bottom: quantitative comparison of trajectories obtained by <rs type="software">ct3d</rs> and the 
active contour approach from Chan and Vese (2001). In general, <rs type="software">ct3d</rs> could 
identify the annotated cells in all time frames (columns # Frames). The 
root mean square distance to the annotated trajectory measures a fraction 
of the diameter of the annotated cell (columns cell and RMS), while the 
Chan-Vese algorithm missed varying numbers of cells or failed completely 
(last column). For the Chan-Vese results, a parameter set was optimized for 
dataset (a). This parameter set (µ = 1, ν = .5, λ 1 = .2, λ 2 = 5) was also applied 
to datasets (b) to (d). While for dataset (a), the result is comparable to <rs type="software">ct3d</rs>, 
the annotated cell was identified in only 29 out of 49 time frames in (b). In 
datasets (c) and (d), the annotated cell could not be identified at all using 
these parameters. See Supplementary Figure S2 for further illustrations. </p>

<p>tracking by Nath et al. (2006) that might yield more accurate cell 
boundaries in some cases. Yet, <rs type="software">ct3d</rs> promises to be a key tool 
for further studying open questions regarding microglia, such as to 
determine if and how glia and microglia share the task of finding 
and removing apoptotic neurons from the vertebrate brain (Peri and 
Nüsslein-Volhard, 2008). 
Beside the direct relevance for in vivo time-lapse microscopy, our 
study indicates that our morphological approach to cosegmentation 
is both practical and of relevance in bioimaging. Consequentially, 
it appears a natural approach to apply cosegmentation to protein 
colocalization studies, which have attracted considerable attention </p>

<p>in recent years following the availability of two-or multi-label 
fluorescence microscopy (Zinchuk and Zinchuk, 2008). 
Another major experience that can be drawn from our work is 
the obvious potential of component trees and the closely connected 
theory of component filters in bioimaging. While component filters 
are well known to leave relevant gradients unchanged, recent work 
such as the results by Coupier et al. (2005) allow to assign a 
statistical significance to components observed in an image. Such 
concepts might be particularly useful when combining component 
trees with cosegmentation for judging the relevance of colocalized 
segments observed when comparing two component trees. </p>

<p>ACKNOWLEDGEMENTS </p>

<p>We are grateful to Dr. F. Peri for providing transgenic zebrafish 
line Tg(ApoE:EGFP). We acknowledge helpful remarks by 
Dr K. Palaniappan on implementing the level set function of the 
Chan-Vese method. </p>

<p>Funding: This work was supported by grants from the National 
Basic Research Program of China (2006CB806605), the Key State 
Research Program of China (2006CB943802), and a Wet Lab 
Collaboration Grant (2009GS-YJ-03) by the Shanghai Institutes for 
Biological Sciences. </p>

<p>Conflict of Interest: none declared. </p>









</text></tei>